{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Gathering Data"
      ],
      "metadata": {
        "id": "jOSx6GFA8aTB"
      },
      "id": "jOSx6GFA8aTB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with importing the required libraries. "
      ],
      "metadata": {
        "id": "iw3CqUK5rWP9"
      },
      "id": "iw3CqUK5rWP9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer the questions in the text-field represented with bullet-points. \n",
        "# Double click on the text-field to edit it. \n"
      ],
      "metadata": {
        "id": "Qmv5xqIur8DH"
      },
      "id": "Qmv5xqIur8DH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc576d5",
      "metadata": {
        "id": "3fc576d5"
      },
      "outputs": [],
      "source": [
        "# \n",
        "# Import Packages\n",
        "# These packages are like libraries. They contain many useful functions that\n",
        "# streamline our codes. \n",
        "\n",
        "import numpy as np                #helps to crunch numbers\n",
        "import matplotlib.pyplot as plt   # helps to plot simple bar graphs\n",
        "import seaborn as sns             # helps to plot scatter plots\n",
        "import pandas as pd               # Will be used to create our DataFrame\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffff6547",
      "metadata": {
        "id": "ffff6547"
      },
      "outputs": [],
      "source": [
        "# First we create an Array of strings. Can you guess what the strings represent?\n",
        "\n",
        "# These are the names of our columns, or Features. The names have been shortened.\n",
        "# Length(m), Wheel_Base(m), Doors, Weight(100kg), Seats, Engine_Size(1000cc), Sun_Roof, Price\n",
        "column_features = ['Len(m)', 'Wb(m)', 'Door', 'W(100kg)', 'Seats','E_S(1000cc)','S_F','Price'] # As per the cars dataset information\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233f3a3f",
      "metadata": {
        "id": "233f3a3f"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "# Next we upload the cars data into a DataFrame called 'df'\n",
        "# A DataFrame is just a table of information. our table will have Features and Class Labels\n",
        "\n",
        "df = pd.read_csv('cars_dl5.csv', names=column_features)  #Using Pandas (as pd), i will open a data file called cars.csv file \n",
        "# i will also name the columns in my data 'column_features'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Preparing Data"
      ],
      "metadata": {
        "id": "bec_-Wf18h4K"
      },
      "id": "bec_-Wf18h4K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf735fb2",
      "metadata": {
        "id": "cf735fb2"
      },
      "outputs": [],
      "source": [
        "df.head(5) #the Head function will showcase the first 5 rows of data\n",
        "\n",
        "# try changing the number '5' parameter to '10' or even '-10'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What are the rows that are displayed?\n",
        "\n",
        "* Is the table correct?\n",
        "\n",
        "* Is the data the correct data that is imported?:\n",
        "\n",
        "* Are the names of the columns correctly assigned?:\n"
      ],
      "metadata": {
        "id": "wm4zXVL0roMJ"
      },
      "id": "wm4zXVL0roMJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a06c46",
      "metadata": {
        "id": "c1a06c46"
      },
      "outputs": [],
      "source": [
        "# Some basic statistical analysis about the data\n",
        "# Before we start applying Machine Learning, we as data enginners should investigate\n",
        "# some details about our data. \n",
        "# The common investigations we can make about the count and mean of our data.\n",
        "\n",
        "# use the describe() funtion to get a snapshot of our data's statistical analysis\n",
        "df.describe()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What does count refer to?\n",
        "\n",
        "* How many rows of data does df contain?\n",
        "\n",
        "* Is there enough data to make a good analysis?\n",
        "\n",
        "* What is mean? \n",
        "\n",
        "* How useful is it to look at the mean values of each column for this dataset?"
      ],
      "metadata": {
        "id": "w0Oqj74Rr4Fb"
      },
      "id": "w0Oqj74Rr4Fb"
    },
    {
      "cell_type": "code",
      "source": [
        "# The describe-table above does not help us to understand the data much.\n",
        "# It was useful in showing me the min and max values\n",
        "# But mean, std were not useful.\n",
        "\n",
        "# Lets dig deeper!, lets find out how many rows of data exists for the \n",
        "# 3 classes of data. Expensive, Moderate, Cheap\n",
        "\n",
        "\n",
        "# count_of_cars is a variable to hold the number of rows where the class is\n",
        "#\"Expensive\", \"Moderate\", \"Cheap\"\n",
        "# Change the word 'Expensive' to the name of the column you want to check.\n",
        "count_of_cars = len(df[df[\"Price\"]==\"Expensive\"])\n",
        "\n",
        "print(count_of_cars)"
      ],
      "metadata": {
        "id": "UxR1d-tCuEY7"
      },
      "id": "UxR1d-tCuEY7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* How many cars are there in the Expensive class?\n",
        "\n",
        "* How many cars are there in the Moderate class?`\n",
        "\n",
        "* How many cares are there in the Cheap class?\n",
        "\n",
        "* Are the columns equal? Will that effect our results?"
      ],
      "metadata": {
        "id": "nMdPMYCYvuAm"
      },
      "id": "nMdPMYCYvuAm"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LylJvfUouD3K"
      },
      "id": "LylJvfUouD3K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a80742",
      "metadata": {
        "id": "84a80742"
      },
      "outputs": [],
      "source": [
        "# Visualize the whole dataset\n",
        "\n",
        "sns.pairplot(df, hue='Price')   # Using the Seaborn library, we can plot comparitive charts of our data\n",
        "\n",
        "# The Seaborn library (as sns) quickly plots each row of data and compares it to each other. \n",
        "# How does looking at the comparisons of Sepal length VS Sepal Width help us?\n",
        "# How does looking at the comparison of Petal Length VS Petal Width help us?\n",
        "\n",
        "# The comparisons help us to infer if the data has seperations or is too closely linked to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Look at the chart for Len(m) VS Wb(M). Is there a clear seperation of the 3 classes?:\n",
        "\n",
        "* Look at Len(m) VS E_S(1000cc). Is there a clear seperations of the 3 classes?:\n",
        "\n",
        "* Look at Wb(m) VS Wb(m). This chart compares only the Wheel_base(m) of all 3 classes. Are the datapoints dignificantly overlapping with each other?\n",
        "\n",
        "* Look at E_S(1000cc) VS E_S(1000cc). Are the datapoints showing significant overlapping with each other?\n",
        "\n",
        "* Which graphs show us a seperation of datapoints of the 3 classes?\n",
        "\n",
        "* Overall, do you think the data of the 3 classes are seperated enough that our Machine Learning model can make good predictions?"
      ],
      "metadata": {
        "id": "ao4vHDQ32dbP"
      },
      "id": "ao4vHDQ32dbP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc524007",
      "metadata": {
        "id": "cc524007"
      },
      "outputs": [],
      "source": [
        "# Seperate features and target  \n",
        "\n",
        "# Before we bgin Machine Learning, we need to spilt up the table into 2 Arrays\n",
        "data = df.values    # Take the values from the table and create a new table called 'data'\n",
        "X = data[:,0:7]     # Take on the first 4 columns (Features) and store it in X\n",
        "Y = data[:,7]       # Take on the Class columns and store it in Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbef406",
      "metadata": {
        "id": "0fbef406"
      },
      "outputs": [],
      "source": [
        "# Calculate avarage of each features for all classes\n",
        "\n",
        "# Using the X and Y arrays created in the previous cell, we are going to plot the averages of each column. \n",
        "# In this cell, we use some array calculations to help us find the averages. \n",
        "Y_Data = np.array([np.average(X[:, i][Y==j].astype('float32')) for i in range (X.shape[1]) for j in (np.unique(Y))])\n",
        "Y_Data_reshaped = Y_Data.reshape(7,3)\n",
        "Y_Data_reshaped = np.swapaxes(Y_Data_reshaped, 0, 1)\n",
        "X_axis = np.arange(len(column_features)-1)\n",
        "width = 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91907fe7",
      "metadata": {
        "id": "91907fe7"
      },
      "outputs": [],
      "source": [
        "# Plot the avarage\n",
        "# Using the MatPlotLib library (as plt) we can plt the averages of each type of Price of car based on its features. \n",
        "plt.bar(X_axis, Y_Data_reshaped[0], width, label = 'Cheap')\n",
        "plt.bar(X_axis+width, Y_Data_reshaped[1], width, label = 'Moderate')\n",
        "plt.bar(X_axis+width*2, Y_Data_reshaped[2], width, label = 'Expensive')\n",
        "plt.xticks(X_axis, column_features[:7])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend(bbox_to_anchor=(1.3,1))\n",
        "plt.show()\n",
        "\n",
        "# Study the table below. in the x-axis, we have the Features, in the Y-axis we have the Value. \n",
        "# Each bar represents the average of that Feature for each Price of the car.\n",
        "# For example, only looking at Len(m), i can see that the average Len(m) of each type of car is\n",
        "#   between 4-5 meters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What does the bar chart above show you?\n",
        "\n",
        "* Can you determine which feature has about the same averages per Price of car?\n",
        "\n",
        "* Can you determine which feature has varying averages per Price of car?"
      ],
      "metadata": {
        "id": "kz3uTz5-4Jod"
      },
      "id": "kz3uTz5-4Jod"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great job!\n",
        "\n",
        "So far we have loaded the flower datas into DataFrames.\n",
        "We have plotted them into different graphs to find similarities and differences.\n",
        "What do you think, are the Features of the flowers seperate enough that\n",
        "we can use the data in our Machine Learning model?\n",
        "\n",
        "Or do you think that the data for each flower is too similar to each other, there is no way our Machine Learning model can correctly differentiate between flowers?"
      ],
      "metadata": {
        "id": "kxYOu4HAs0Mm"
      },
      "id": "kxYOu4HAs0Mm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Choosing a Model"
      ],
      "metadata": {
        "id": "FHy7iHRl9K7T"
      },
      "id": "FHy7iHRl9K7T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd891de5",
      "metadata": {
        "id": "dd891de5"
      },
      "outputs": [],
      "source": [
        "# Split the data to train and test dataset.\n",
        "# Before we can apply Machine Learning, we need to split our dataset into Training and Testing data\n",
        "# Training data is the data used to train our Machine\n",
        "# Testing data will be later used to validate whether our Machine is well trained or not.\n",
        "\n",
        "# We will use the sklearn library to split our data into Training and Testing.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)   #split based on 70:30 ratio. \n",
        "\n",
        "#80% data for Training\n",
        "# 20% data for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "979f8191",
      "metadata": {
        "id": "979f8191"
      },
      "outputs": [],
      "source": [
        "# Support vector machine algorithm\n",
        "from sklearn.svm import SVC   # using the SKLearn library to call the Support Vector Machine algorithms\n",
        "svn = SVC()\n",
        "svn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6065a00c",
      "metadata": {
        "id": "6065a00c"
      },
      "outputs": [],
      "source": [
        "# Predict from the test dataset\n",
        "predictions = svn.predict(X_test) # Now that our Training is complete, it is time to test our data.\n",
        "\n",
        "# Using the 30% of data seperated for Testing in cell 10, it is time for us\n",
        "# to use it to predict how well we can identify our Price of cars given the features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c16110a",
      "metadata": {
        "id": "4c16110a"
      },
      "outputs": [],
      "source": [
        "# Calculate the accuracy\n",
        "# Think of accuracy as shooting arrows at a target. We dont want the arrows\n",
        "# to be far from the bullseye!\n",
        "\n",
        "# So the higher the Accuracy is to 1 (1 means 100% accurate), the better our test went.\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoorah! Our Machine Learning model has been created!\n",
        "\n",
        "What was your Accuracy results? \n",
        "Where they close to 1 (100%)?\n",
        "Are you satisfied with your results?\n",
        "\n",
        "In the real-world, finding an accuracy of more than 0.9 is really really good!"
      ],
      "metadata": {
        "id": "XR34YYaLuahQ"
      },
      "id": "XR34YYaLuahQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Evaluation"
      ],
      "metadata": {
        "id": "djwIr5iZ9Pu4"
      },
      "id": "djwIr5iZ9Pu4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26189e59",
      "metadata": {
        "id": "26189e59"
      },
      "outputs": [],
      "source": [
        "# A detailed classification report\n",
        "\n",
        "# Time to tabulate the results from our tests and predictions\n",
        "# We only need to look at Precision and Recall\n",
        "\n",
        "# What is the Precision and Recall of the 3 flowers?\n",
        "# Which flower has the lowest Precision and Recall? What does that mean?\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5 Deployment"
      ],
      "metadata": {
        "id": "Mrsh9QdMfiN0"
      },
      "id": "Mrsh9QdMfiN0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If i gave you data on new cars\\, can you predict their class (Price)"
      ],
      "metadata": {
        "id": "vmeYIkRufZNQ"
      },
      "id": "vmeYIkRufZNQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e299fe87",
      "metadata": {
        "id": "e299fe87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb40476-8208-4938-b704-cb61acdfbe83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction of Species: ['Expensive' 'Moderate' 'Cheap']\n"
          ]
        }
      ],
      "source": [
        "# Lets create an Array of data of 3 types of Prices/cars. \n",
        "# For each dimension of the Array, i only have 7 columns, each col represents\n",
        "# the features of the car. \n",
        "\n",
        "#Run the cell and lets see how well our Machine predicts the Prices of these cars. \n",
        "\n",
        "X_new = np.array([[4.331,1.958,2,9,2,4.1,1],[3.617,1.484,4,11.52,4,2.9,0],[3.546,1.675,4,15.79,8,1.6,0]])\n",
        "\n",
        "\n",
        "#Prediction of the species from the input vector\n",
        "prediction = svn.predict(X_new)\n",
        "print(\"Prediction of Species: {}\".format(prediction)) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SO what does the prediction show? \n",
        "\n",
        "Use the ten rows of data given. Input 3 rows at a time int he X_new array.\n",
        "What are the results of your prediction? are they true? check your answers with your teacher? \n"
      ],
      "metadata": {
        "id": "72wphpzNvhKY"
      },
      "id": "72wphpzNvhKY"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ENvCIBzBvg2d"
      },
      "id": "ENvCIBzBvg2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore this part"
      ],
      "metadata": {
        "id": "bHNQCMI__QAT"
      },
      "id": "bHNQCMI__QAT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ede659b",
      "metadata": {
        "id": "2ede659b"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "import pickle\n",
        "with open('SVM.pickle', 'wb') as f:\n",
        "    pickle.dump(svn, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e59be3b",
      "metadata": {
        "id": "6e59be3b"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "with open('SVM.pickle', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7897500c",
      "metadata": {
        "id": "7897500c"
      },
      "outputs": [],
      "source": [
        "model.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863bc902",
      "metadata": {
        "id": "863bc902"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('dsenv': conda)",
      "language": "python",
      "name": "python3710jvsc74a57bd03de85ba066d17394542b6ba22a9c606e6ab49ee752c0de84f0bbe3e820d7ebf9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}